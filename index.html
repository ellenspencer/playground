<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
  <title>VisuoMotor Lab</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>
  <!-- Add the following link tag to specify the favicon -->
	<link rel="icon" href="img/favicon.ico">
</head>
<body>

<!-- Navigation -->
	<nav class="navbar navbar-inverse navbar-static-top" role="navigation">
	  <div class="container">
		<div class="navbar-header">
		  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
		  <ul class="nav navbar-nav">
				  <!--<li><a href="index.html">Home</a></li>-->
				  <li><a href="#themes">Research Themes</a></li>
				  <li><a href="#preprints">Publications</a></li> 
				  <li><a href="#people">People</a></li> 
				  <!--<li><a href="#">CV</a></li>--> 
		  </ul>
		</div>
	  </div>
	</nav>
  
  <!-- Page Content -->
    <div class="container">

        <div class="row">

            <!-- Entries Column -->
            <div class="col-md-7" style="height: 100vh;">

                <!-- Main Image -->
                <img class="img-responsive" src="img\Iris_-_right_eye_of_a_girl1.jpg" alt="Credit: Laitr Keiows." width="550" height="300"><br>
                <div style="margin-top:3%; text-align:justify; max-width: 550px;">                
					      <p>The VisuoMotor Lab investigates interactions between visual perception and eye movements using psychophysical and eyetracking methods. The current focus is on understanding visuo-motor learning and adaptation in performing tasks consolidated over human evolution (e.g. dealing with re-afferent motion during pursuit eye movements), one lifetime (e.g. crossing the road), or over a few hours of training (e.g. gaze-control).</p>

                </div>
            </div> 

            <!-- Contact Info on the Sidebar -->
            <div class="col-md-5">
                <div style="font-family: 'Oswald', sans-serif; font-size: 32px;"><b>VisuoMotor Lab</b></div><br>
                <p><b>David Souto</b><br>
                <b>Lecturer in Psychology</b><br>
                <p>School of Psychology and Vision Sciencest<br>
                University of Leicester<br>
                Lancaster Rd<br>
                Leicester<br>
                United Kingdom<br>  
                </p>
                <p>
                <a href="mailto:d.souto@le.ac.uk">d.souto@le.ac.uk </a><br>
                ++44 (0) 116 229 7184<br>
                </p>
            </div>
            
            <!-- Links on the Sidebar -->
            <div class="col-md-4" style="margin-top:2%">
              <div style="display: flex; flex-direction: column; align-items: left;">
                <div style="display: flex;">
                  <a href="https://scholar.google.com/citations?user=CtG3hB0AAAAJ&amp;hl=en" style="margin-right: 10px;"><i class="fas fa-graduation-cap"></i> <b>Google Scholar</b></a>
                  <a href="https://www.researchgate.net/profile/David-Souto-2"><i class="fas fa-file-alt"></i><b>ResearchGate</b></a>
                </div>
                <div style="display: flex;">
                  <a href="https://twitter.com/david_souto" style="margin-right: 10px;"><i class="fab fa-twitter"></i><b>Twitter</b></a>
                  <a href="https://mastodon.online/@david_souto"><i class="fab fa-mastodon"></i><b>Mastodon</b></a>
                </div>
                <div style="display: flex;">
                  <a href="https://www.linkedin.com/in/david-souto-b5b61318/" style="margin-right: 10px;"><i class="fab fa-linkedin"></i> <b>LinkedIn</b></a>
                  <a href="https://github.com/DavidSouto"><i class="fab fa-github"></i><b>GitHub</b></a>
                </div>
              </div>
            </div>
            <!--<div class="col-md-4" style="margin-top:2%">
              <dd><a href="https://scholar.google.com/citations?user=CtG3hB0AAAAJ&amp;hl=en">Google Scholar</a></dd> 
              <dd><a href="https://twitter.com/david_souto">Twitter</a></dd>
              <dd><a href="https://mastodon.online/@david_souto">Mastodon</a></dd>
              <dd><a href="https://www.linkedin.com/in/david-souto-b5b61318/">LinkedIn</a></dd>
              <dd><a href="https://www.researchgate.net/profile/David-Souto-2">ResearchGate</a></dd>
              <dd><a href="https://github.com/DavidSouto">GitHub</a></dd>
            </div>-->
            
            <!-- Publications -->
            <div class="col-md-8" style="height: 100vh;">  
                
                <h2 id="preprints">Pre-prints</h2>

                <p>Tipura, E., Souto, D., &amp; Fox, E. (2022, October 3). Trait anxious people take longer to search for happy faces in the presence of neutral and fearful distractors. PsyArxiv. <a href="https://psyarxiv.com/p76eb/">Psyarxiv.com/p76eb</a></p>

                <p>Souto, D.,&nbsp; Sudkamp, J., Nacilla, K., &amp; Bocian, M. (2021, June 13). Tuning to a hip-hop beat: Pursuit eye movements reveal processing of biological motion. PsyArxiv. <a href="https://psyarxiv.com/4bf69">PsyArxiv.com/4bf69</a></p>

                <p>Sudkamp, J., &amp; Souto, D. (2021, November 30). Pedestrian's overt attention affects time-to-arrival estimates of oncoming traffic. PsyArxiv, <a href="https://psyarxiv.com/a2zsh/">PsyArxiv.com/a2zsh</a></p>

                <h2 id="publications">Publications</h2>

                <p>Bruno, A., Sudkamp, J., &amp; Souto, D. (2023). A metacognitive approach to the study of motion-induced duration biases reveals inter-individual differences in forming confidence judgments.&nbsp;<em>Journal of Vision</em>,&nbsp;<em>23</em>(3), 15-15. <a href="https://doi.org/10.1167/jov.23.3.15">https://doi.org/10.1167/jov.23.3.15 [Open Access]</a></p>

                <p>Sudkamp, J., Souto, D. (2023). The effect of contrast on pedestrians&rsquo; perception of vehicle speed in different road environments. Transportation Research Part F Traffic Psychology and Behaviour 92:15-26. DOI: 10.1016/j.trf.2022.10.017 [<a href="pdfs/Sudkamp.Souto_.2023.postprint.pdf">post-print</a>]</p>

                <p>Barrett, D.J.K., Souto D., Pilling, M., Baguley, M. D. (2022). An Exploratory Investigation of Pupillometry As a Measure of Tinnitus Intrusiveness on a Test of Auditory Short-Term Memory. Ear and Hearing, https://doi.org/10.1097/AUD.0000000000001214. <a href="https://www.researchgate.net/publication/358870677_An_Exploratory_Investigation_of_Pupillometry_As_a_Measure_of_Tinnitus_Intrusiveness_on_a_Test_of_Auditory_Short-Term_Memory">[postprint]</a></p>

                <p>Sudkamp, J., Bocian, , D., &amp; Souto, D. (2021). The role of eye movements in perceiving vehicle speed and time-to-arrival at the roadside. Scientific Reports, 11 (23312). <a href="https://doi.org/10.1038/s41598-021-02412-x" data-track="click" data-track-action="view doi" data-track-label="link">https://doi.org/10.1038/s41598-021-02412-x (Open Access Link)</a></p>

                <p>Souto, D., &amp; Kerzel, D. (2021). Visual selective attention and the control of tracking eye movements: A critical review. Journal of Neurophysiology. <a href="https://doi.org/10.1152/jn.00145.2019">https://doi.org/10.1152/jn.00145.2019. [</a><a href="pdfs/souto.kerzel.2021.pdf">full-text</a>]</p>

                <p>Souto, D., Marsh, O., Hutchinson, C., Judge, S., &amp; Paterson, K. (2021). Cognitive plasticity induced by gaze-control technology: Gaze-typing improves performance in the antisaccade task. Computers in Human Behaviour. <a href="https://doi.org/10.1016/j.chb.2021.106831" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/j.chb.2021.106831</a> [<a href="pdfs/souto.marsh_.hutchinson.judge_.paterson.2021.pdf">full-text</a>][<a href="https://github.com/DavidSouto/eye-writing-task">code (github)</a>][<a href="https://osf.io/e8vba/">data &amp; pre-reg (osf)</a>]</p>

                <p>Luna R, Serrano-Pedraza, I., Gegenfurtner, K. R., Sch&uuml;tz, A. C., &amp; Souto, D. (2021). Achieving visual stability during smooth pursuit eye movements: Directional and confidence judgements favor a recalibration model. Vision Research, 184, 58-73. <a href="https://doi.org/10.1016/j.visres.2021.03.003">https://doi.org/10.1016/j.visres.2021.03.003</a> [<a href="pdfs/luna.serrano-pedraza.gegenfurtner.schutz.souto_.2021.VR_.pdf">full-text</a>][<a href="https://zenodo.org/record/4672698">data</a>]</p>

                <p>Souto D., &amp; Sch&uuml;tz, A. C. (2020). Task-relevance is causal in eye movement learning and adaptation. In Federmeier, K., &amp; Schotter, E. (Eds.). Psychology of Learning and Motivation, Volume 73. https://doi.org/10.1016/bs.plm.2020.06.002 [<a href="pdfs/souto.schutz.2020.pdf">full-text</a>]</p>

                <p>Souto, D., Smith, L., Sudkamp, J., &amp; Bloj, M. (2020). Ambiguity in high definition: Gaze determines physical interpretation of ambiguous rotation even in the absence of a visual context. Psychonomic Bulletin &amp; Review, 27,&nbsp;1239&ndash;1246. [<a href="pdfs/Souto2020_Article_AmbiguityInHighDefinitionGazeD.pdf">full-text</a>][<a href="https://doi.org/10.25392/leicester.data.11316557.v1">demo (figshare)</a>; <a href="https://osf.io/sz8h9/">code and data (osf)</a>]</p>

                <p>Souto, D., Chudasama, J., Kerzel, D., &amp; Johnston, A. (2019). Motion integration is anisotropic during smooth pursuit eye movements. Journal of Neurophysiology, 121(5), 1787-1797.[<a href="https://www.physiology.org/doi/pdf/10.1152/jn.00591.2018?casa_token=HGrqjCncEA4AAAAA:D6PfVi8PY43r1_N23SLMdyzxmBC1hDtIeJBxwbIzb3xEG_qvESRJFPiX4fFxt7oUNmrnn0WKzTR2">html</a>][<a href="https://leicester.figshare.com/articles/Motion_integration_is_anisotropic_during_smooth_pursuit_eye_movements/7718453">demo</a>][<a href="pdfs/souto.chudasama.kerzel.johnston.2019.pdf">pdf</a>]</p>

                <p>Souto, D., Born, S., &amp; Kerzel, D. (2018). The contribution of forward masking to saccadic inhibition of return. Attention, Perception, &amp; Psychophysics, 80(5), 1182-1192 [<a href="https://link.springer.com/article/10.3758/s13414-018-1490-2">full-text</a>]</p>

                <p>Souto, D., Gegenfurtner, K. R., Sch&uuml;tz, A. C. (2016). Saccade adaptation and visual uncertainty. Frontiers in Human Neuroscience, 10:3387, doi: 10.3389/fnhum.2016.00227 [<a href="http://journal.frontiersin.org/article/10.3389/fnhum.2016.00227/full">full-text</a>][<a href="https://www.frontiersin.org/articles/10.3389/fnhum.2016.00227/pdf">pdf</a>]</p>

                <p>Sch&uuml;tz, A. C., Souto, D. (2015). Perceptual task induces saccadic adaptation by target selection. Frontiers in Human Neuroscience, 9:566. doi: 10.3389/fnhum.2015.00566 [<a href="http://journal.frontiersin.org/article/10.3389/fnhum.2015.00566/abstract">full-text</a>][<a href="https://www.frontiersin.org/articles/10.3389/fnhum.2015.00566/pdf">pdf</a>]</p>

                <p>Souto, D., &amp; Kerzel, D. (2014). Ocular tracking responses to background motion gated by feature-based attention. Journal of Neurophysiology , 112 (5) 1074-1081; doi:10.1152/jn.00810.2013 [<a href="http://jn.physiology.org/content/112/5/1074.full">full-text</a>][<a href="pdfs/souto.kerzel.2014.pdf">pdf</a>]</p>

                <p>Sch&uuml;tz, A. C., Kerzel, D., &amp; Souto, D. (2014). Saccadic adaptation induced by a perceptual task. Journal of Vision, 14(5):4, 1-19.[<a href="http://jov.arvojournals.org/article.aspx?articleid=2121659">html</a>][<a href="pdfs/schutz.kerzel.souto_.2014.pdf">pdf</a>]</p>

                <p>Souto, D., &amp; Kerzel, D. (2013). Like a rolling stone: Naturalistic visual kinematics facilitate tracking eye movements. Journal of Vision, 13(2), 1-12.[<a href="https://jov.arvojournals.org/article.aspx?articleid=2193826">html</a>][<a href="https://jov.arvojournals.org/arvo/content_public/journal/jov/933541/i1534-7362-13-2-9.pdf">pdf</a>]</p>

                <p>Souto, D., &amp; Johnston, A. (2012). Masking and color inheritance along the apparent motion path. Journal of Vision, 12(7), 1-18.[<a href="http://jov.arvojournals.org/article.aspx?articleid=2192156">html</a>][<a href="pdfs/Souto.Johnston.2012.pdf">pdf</a>]</p>

                <p>Kerzel, D., Schonhammer, J., Burra, N., Born, S., &amp; Souto, D. (2011). Saliency changes appearance. PLoS One, 6(12), e28292.[<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0028292">html</a>][<a href="pdfs/kerzel.shonhammer.burra_.born_.souto_.2011.pdf">pdf</a>]</p>

                <p>Sch&uuml;tz, A. C., &amp; Souto, D. (2011). Adaptation of catch-up saccades during the initiation of smooth pursuit eye movements. Experimental Brain Research, 209(4), 537-549.[<a href="https://link.springer.com/article/10.1007%2Fs00221-011-2581-7">html</a>][<a href="pdfs/schutz.souto_.2011.pdf">pdf</a>]</p>

                <p>Souto, D., &amp; Kerzel, D. (2011). Attentional constraints on target selection for smooth pursuit eye movements. Vision Research, 51(1), 13-20.[<a href="http://www.sciencedirect.com/science/article/pii/S0042698910004621?via%3Dihub">html</a>][<a href="pdfs/souto.kerzel.2011.pdf">pdf</a>]</p>

                <p>van Diepen, R. M., Born, S., Souto, D., Gauch, A., &amp; Kerzel, D. (2010). Visual flicker in the gamma-band range does not draw attention. Journal of Neurophysiology, 103(3), 1606-1613.[<a href="http://jn.physiology.org/content/103/3/1606.long">html</a>][<a href="pdfs/vanDiepen.Born_.Souto_.Gauch_.Kerzel.2010.pdf">pdf</a>]</p>

                <p>Kerzel, D., Born, S., &amp; Souto, D. (2010). Inhibition of steady-state smooth pursuit and catch-up saccades by abrupt visual and auditory onsets. Journal of Neurophysiology, 104(5), 2573-2585.[<a href="http://jn.physiology.org/content/104/5/2573.long">html</a>][<a href="pdfs/kerzel.born_.souto_.2010.pdf">pdf</a>]</p>

                <p>Kerzel, D., Born, S., &amp; Souto, D. (2009). Smooth pursuit eye movements and perception share target selection, but only some central resources. Behavioural Brain Research, 201(1), 66-73.[<a href="http://www.sciencedirect.com/science/article/pii/S0166432809000710?via%3Dihub">html</a>][<a href="pdfs/kerzel.born_.souto_.2009.pdf">pdf</a>]</p>

                <p>Kerzel, D., Zarian, L., &amp; Souto, D. (2009). Involuntary cueing effects on accuracy measures: Stimulus and task dependence. Journal of Vision, 9(11), 16 11-16.[<a href="http://jov.arvojournals.org/article.aspx?articleid=2203952">html</a>][<a href="pdfs/kerzel.zarian.souto_.2009.pdf">pdf</a>]</p>

                <p>Souto, D., &amp; Kerzel, D. (2009). Evidence for an attentional component in saccadic inhibition of return. Experimental Brain Research, 195(4), 531-540.[<a href="https://link.springer.com/article/10.1007%2Fs00221-009-1824-3">html</a>][<a href="pdfs/souto.kerzel.2009b.pdf">pdf</a>]</p>

                <p>Souto, D., &amp; Kerzel, D. (2009). Involuntary cueing effects during smooth pursuit: facilitation and inhibition of return in oculocentric coordinates. Experimental Brain Research, 192(1), 25-31.[<a href="https://link.springer.com/article/10.1007%2Fs00221-008-1555-x">html</a>][<a href="pdfs/Souto.Kerzel.2009.pdf">pdf</a>]</p>

                <p>Kerzel, D., Souto, D., &amp; Ziegler, N. E. (2008). Effects of attention shifts to stationary objects during steady-state smooth pursuit eye movements. Vision Research, 48(7), 958-969.[<a href="http://www.sciencedirect.com/science/article/pii/S0042698908000436?via%3Dihub">html</a>][<a href="pdfs/kerzel.souto_.ziegler.2008.pdf">pdf</a>]</p>

                <p>Souto, D., &amp; Kerzel, D. (2008). Dynamics of attention during the initiation of smooth pursuit eye movements. Journal of Vision, 8(14), 3 1-16.[<a href="http://jov.arvojournals.org/article.aspx?articleid=2193339">html</a>][<a href="pdfs/souto.kerzel.2008.pdf">pdf</a>]</p>

                <h2 id = "themes"> Research Themes </h2>
                <p>The VisuoMotor Lab investigates the interactions between visual perception and eye movements using psychophysical and eyetracking methods. The current focus is on understanding visuo-motor learning and adaptation&nbsp;in performing tasks consolidated over human evolution (e.g. dealing with re-afferent motion during pursuit), one's&nbsp;lifetime (e.g. crossing the road),&nbsp;or over a few hours of training (e.g. gaze-typing). Finally, we attempt to bridge the gap between fundamental and applied research by adapting our paradigms to immersive virtual reality (VR).</p>

                <h2>Eye movement learning and adaptation</h2>

                <p> We move our eyes very efficiently and constantly to gather visual information. This is done effortlessly and mostly unconsciously, hiding the constant adjustment of eye movements that ensures accurate acquisition of visual targets (<a href="http://journal.frontiersin.org/article/10.3389/fnhum.2016.00227/full">Souto, Gegenfurtner and Schütz, 2016</a>). We have studied the role of top-down control and visual uncertainty on saccadic adaptation, showing that task-demands alone can generate saccadic adaptation. More recently, we have extended the investigation of eye movement learning to the more complex task of controlling a human-computer interface with gaze.</p>

                <h3><i>Sensorymotor learning: Visual and attentional control </i></h3>

                <p>Souto, D., Gegenfurtner, K. R., Schütz, A. C. (2016). Saccade adaptation and visual uncertainty. Frontiers in Human Neuroscience, 10:3387, doi: 10.3389/fnhum.2016.00227 [<a href="http://journal.frontiersin.org/article/10.3389/fnhum.2016.00227/full" data-wplink-edit="true">full-text</a>][<a href="https://www.frontiersin.org/articles/10.3389/fnhum.2016.00227/pdf">pdf</a>]</p>
                <p>Schütz, A. C., Souto, D. (2015). Perceptual task induces saccadic adaptation by target selection. Frontiers in Human Neuroscience, 9:566. doi: 10.3389/fnhum.2015.00566 [<a href="http://journal.frontiersin.org/article/10.3389/fnhum.2015.00566/abstract">full-text</a>][<a href="https://www.frontiersin.org/articles/10.3389/fnhum.2015.00566/pdf">pdf</a>]</p>
                <p>Schütz, A. C., &amp; Souto, D. (2011). Adaptation of catch-up saccades during the initiation of smooth pursuit eye movements. Experimental Brain Research, 209(4), 537-549.[<a style="background-color: #ffffff; font-size: 1rem;" href="https://link.springer.com/article/10.1007%2Fs00221-011-2581-7">html</a>][<a style="background-color: #ffffff; font-size: 1rem;" href="pdfs/schutz.souto_.2011.pdf">pdf</a>]</p>

                <h3><i style="font-weight: normal;">Gaze-typing: learning and inhibitory control</i></h3>

                <p>Gaze-interaction is a form of assistive communication technology that proved invaluable in allowing efficient communication in conditions such as motor neuron disease. We recently obtained funding from the British Academy to study the involvement of inhibitory control in learning to type with gaze. We benefited from the guidance of Special Effects and ACE centre in Oxford. The preregistered project can be found&nbsp;<a style="background-color: #ffffff; font-size: 1rem;" href="https://osf.io/f9qm8/">here</a> (Open Science Framework).&nbsp;</p>
                <p>We will be presenting this work at the European Conference on Eye Movements in Alicante (August, 2019).</p>

                <h2>Visual attention</h2>

                <p>We rely on visual attention to select the objects that enter consciousness and guide action. In the past we have explored the coupling between visual attention and eye-movements and the perceptual and oculomotor effects of our attention being drawn by visual transients.</p>

                <h3><i>Visual attention and eye movements coupling</i></h3>

                <p>There is a well-known coupling between the allocation visual attention resources and the programming of eye movements as demonstrated by the brain functional anatomy and behaviour. In several publications we have explored the extent of this coupling in the context of saccadic and smooth pursuit eye movements.</p>

                <p>Souto, D., &amp; Kerzel, D. (2014). Ocular tracking responses to background motion gated by feature-based attention. Journal of Neurophysiology, 112 (5) 1074-1081; doi:10.1152/jn.00810.2013 [<a style="background-color: #ffffff; font-size: 1rem;" href="http://jn.physiology.org/content/112/5/1074.full">full-text</a>][<a style="background-color: #ffffff; font-size: 1rem;" href="pdfs/souto.kerzel.2014.pdf">pdf</a>]</p>
                <p>Souto, D., &amp; Kerzel, D. (2011). Attentional constraints on target selection for smooth pursuit eye movements. Vision Research, 51(1), 13-20.[<a href="http://www.sciencedirect.com/science/article/pii/S0042698910004621?via%3Dihub">html</a>][<a href="pdfs/souto.kerzel.2011.pdf">pdf</a>]</p>
                <p>Kerzel, D., Born, S., &amp; Souto, D. (2009). Smooth pursuit eye movements and perception share target selection, but only some central resources. Behavioural Brain Research, 201(1), 66-73.[<a href="http://www.sciencedirect.com/science/article/pii/S0166432809000710?via%3Dihub">html</a>][<a href="pdfs/kerzel.born_.souto_.2009.pdf">pdf</a>]</p>
                <p>Kerzel, D., Souto, D., &amp; Ziegler, N. E. (2008). Effects of attention shifts to stationary objects during steady-state smooth pursuit eye movements. Vision Research, 48(7), 958-969.[<a href="http://www.sciencedirect.com/science/article/pii/S0042698908000436?via%3Dihub">html</a>][<a href="pdfs/kerzel.souto_.ziegler.2008.pdf">pdf</a>]</p>
                <p>Souto, D., &amp; Kerzel, D. (2008). Dynamics of attention during the initiation of smooth pursuit eye movements. Journal of Vision, 8(14), 3 1-16.[<a href="http://jov.arvojournals.org/article.aspx?articleid=2193339">html</a>][<a href="pdfs/souto.kerzel.2008.pdf">pdf</a>]</p>

                <h3><i>Perceptual and oculomotor effects of exogenous attention</i></h3>

                <p>With colleagues in the University of Geneva we have looked at how distracting visual transients can disrupt current eye movement plans and impact perceptual appearance and discrimination performance.</p>

                <p>Kerzel, D., Schonhammer, J., Burra, N., Born, S., &amp; Souto, D. (2011). Saliency changes appearance. PLoS One, 6(12), e28292.[<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0028292">html</a>][<a href="pdfs/kerzel.shonhammer.burra_.born_.souto_.2011.pdf">pdf</a>]</p>
                <p>van Diepen, R. M., Born, S., Souto, D., Gauch, A., &amp; Kerzel, D. (2010). Visual flicker in the gamma-band range does not draw attention. Journal of Neurophysiology, 103(3), 1606-1613.[<a style="background-color: #ffffff; font-size: 1rem;" href="http://jn.physiology.org/content/103/3/1606.long">html</a>][<a style="background-color: #ffffff; font-size: 1rem;" href="pdfs/vanDiepen.Born_.Souto_.Gauch_.Kerzel.2010.pdf">pdf</a>]</p>
                <p>Kerzel, D., Born, S., &amp; Souto, D. (2010). Inhibition of steady-state smooth pursuit and catch-up saccades by abrupt visual and auditory onsets. Journal of Neurophysiology, 104(5), 2573-2585.[<a href="http://jn.physiology.org/content/104/5/2573.long">html</a>][<a href="pdfs/kerzel.born_.souto_.2010.pdf">pdf</a>]</p>

                <h2>Motion processing and perception</h2>

                <h3><i>Apparent motion</i></h3>

                <p>&nbsp;Souto, D., Smith L., &amp; Bloj, M. (2018, March). Where the rubber meets the road: Visually-inferred friction. Poster presented at the Applied Vision Association Meeting, University of Bradford, UK.[<a style="background-color: #ffffff; font-size: 1rem;" href="pdfs/Souto.Smith_.Bloj_.AVA_.pdf">Souto.Smith.Bloj.AVA</a>]</p>

                <p>Souto, D., &amp; Kerzel, D. (2013). Like a rolling stone: Naturalistic visual kinematics facilitate tracking eye movements. Journal of Vision, 13(2), 1-12.[html][pdf]</p>

                <p>When two dots are presented in succession we can see illusory motion between them. But, to what extent is illusory motion like the real thing? In a discrimination task we showed that illusory motion can mask a target presented at very specific points along the putative apparent motion path. See more here:</p>

                <p>Souto, D., &amp; Johnston, A. (2012). Masking and color inheritance along the apparent motion path. Journal of Vision, 12(7), 1-18.[<a href="http://jov.arvojournals.org/article.aspx?articleid=2192156">html</a>][<a href="pdfs/Souto.Johnston.2012.pdf">pdf</a>]</p>

                <h3><i>Motion perception during smooth pursuit eye movements</i></h3>

                <p>How does the visual system achieve coherent perception of an object’s motion while the eyes themselves are moving? We used a new paradigm to address the question, using multiple-aperture arrays. They allow us to test motion coherence during pursuit which should be unaffected by location information. Reflexive eye movement and perceptual judgements indicated a strong asymmetry in processing global motion during pursuit, suggesting the visual system downplays the influence of motion opposite to pursuit, likely because it is dominated by re-afferent (self-induced) information.</p>

                <p>Video demos can be downloaded on <a href="https://leicester.figshare.com/articles/Motion_integration_is_anisotropic_during_smooth_pursuit_eye_movements/7718453">figshare</a>. To see the low-contrast stimulus you will need to enlarge the video and play it several times before you are able to see coherent motion. The example below shows coherent motion opposite and downward from pursuit direction. Compare this to the second video, showing global motion in the direction of pursuit.&nbsp;</p>

                <p>Souto, D., Chudasama, J., Kerzel, D., &amp; Johnston, A. (2019). Motion integration is anisotropic during smooth pursuit eye movements. Journal of Neurophysiology, 121(5), 1787-1797.[<a style="background-color: #ffffff; font-size: 1rem;" href="https://www.physiology.org/doi/pdf/10.1152/jn.00591.2018?casa_token=HGrqjCncEA4AAAAA:D6PfVi8PY43r1_N23SLMdyzxmBC1hDtIeJBxwbIzb3xEG_qvESRJFPiX4fFxt7oUNmrnn0WKzTR2">html</a>][<a style="background-color: #ffffff; font-size: 1rem;" href="pdfs/souto.chudasama.kerzel.johnston.2019.pdf">pdf</a>]

                <h2>Conference presentations (selection)</h2>

                <p>Almajed, S., Duke, P., Souto, D. (2022). Cyclovergence movements in presence of vertical shear disparity across depth planes. Poster presented at the European Conference on Eye Movements, Leicester, UK.</p>

                <p>Luna, Serrano-Pedraza, Souto (2020). Perceiving motion in the world during smooth pursuit eye movements: Directional and confidence judgements favour a re-calibration model. Poster presented at the Virtual Vision Science Society meeting.&nbsp;</p><p>PDF: <a href="pdfs/Luna_Serrano-Pedraza_Souto_2020.pdf">Luna_Serrano-Pedraza_Souto_2020</a></p>

                <p>Presentation: <a href="pdfs/Luna_Serrano-Pedraza_Souto_2020.pdf">Luna_Serrano-Pedraza_Souto_2020</a></p>

                <p>Souto, Marsh &amp; Paterson (2019, August). Use-dependent plasticity in assistive interfaces: Gaze-typing improves inhibitory control. Poster presented at the European Conference on Eye Movements, Alicante, Spain.</p>

                <p>PDF: <a href="pdfs/Souto.Marsh_.Paterson.2019.ECEM_.pdf">Souto.Marsh.Paterson.2019.ECEM</a></p>

                <p>Sudkamp, Bocian &amp; Souto (2019, August) Visual information sampling at the zebra crossing: Gaze behaviour in speed and time to arrival judgements. Poster presented at the European Conference on Eye Movements, Alicante, Spain.</p>

                <p>PDF: <a href="pdfs/Sudkamp.Bocian.Souto_.2019.ECEM_.pdf">Sudkamp.Bocian.Souto.2019.ECEM</a></p>

                <p><a href="https://leicester.figshare.com/s/b8ab004bbf88e87ce823">DEMO on Figshare</a></p>

                <p>Souto, D., Smith L., &amp; Bloj, M. (2018, March). Where the rubber meets the road: Visually-inferred friction. Poster presented at the Applied Vision Association Meeting, University of Bradford, UK.</p>

                <p>PDF: <a href="pdfs/Souto.Smith_.Bloj_.AVA_.pdf">Souto.Smith.Bloj.AVA</a></p>

                <h2>Media</h2>

                <p>Digital Planet BBC Wold Service Podcast <a href="https://www.bbc.co.uk/programmes/w3csz981">"will gaze tech replace touch tech?" <a></p>

                <p>Blog post: <a href="https://www.thebritishacademy.ac.uk/blog/summer-showcase-2020-eyetrackers-replace-computer-keyboard/">Can eye-trackers replace the computer keyboard?</a></p>

                <p>British Academy <a href="https://youtu.be/SJIVlSTNyUo">Virtual Summer Showcase</a></p>
                
                <h2 id="people">People</h2>

                <h2><strong>David Souto, PhD</strong><br>
                <img class="circle-image alignright size-full" src="img/cropped-souto-e1533808235512.jpg" alt="Jennifer Sudkamp" width="100" height="100">
                <p>&nbsp</p>    
                <p>David is a Lecturer within the School of Psychology and Vision Sciences at the University of Leicester. He is a member of the Vision Sciences research group. He is partial to writing about himself in the third person.</p>

                <h2><strong>Jennifer Sudkamp, MSc</strong><br>PhD student, CLS studentship</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full" src="img/Jennifer-e1538323006680.png" alt="Jennifer Sudkamp" width="100" height="100">
                <p>&nbsp</p>    
                <p>Jennifer completed her MSc in Psychology at the University of Vienna, where she applied an eye-tracking methodology to investigate consumers’ attention allocation to social cues in online advertisements. She continued her studies at the Norwegian University of Science and Technology (NTNU) exploring the role of the visual road environment in the perception of driving speed. During the course of her PhD project at the University of Leicester, Jennifer will be working in collaboration with the Biomechanics and Immersive Technology Laboratory (<a href="https://www2.le.ac.uk/departments/engineering/research/biomechit-lab-1/biomechanics-and-immersive-technology-laboratory-biomechit">BiomechIT Lab</a>), led by Mateusz Bocian, to study eye-movement and walking behaviour during road-crossing by using immersive VR.</p>

                <h2><strong>Saad Almajed, MSc</strong><br>PhD student, King Saud University Scholarship</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full wp-image-195" src="img/saad_cropped.jpg" alt="Saad Almajed" width="100" height="100">
                <p>&nbsp</p>    
                <p>Saad is a current PhD student at the University of Leicester. His work is supervised by <a href="https://www2.le.ac.uk/departments/npb/people/pad11">Phil Duke</a> and David Souto (co-supervisor). He is interested in investigating how the visual system use vertical disparities provided by the two retinal images to perceive the inclination of surfaces separated in various depth planes. He is also interested in measuring the effect of the vertical shear disparities on cyclovergence (the movement of the eyes in the opposite directions about the line of sight) using Pupil Labs eye trackers.</p>

                <h2><strong>Tamara Gheorghes, PhD</strong><br>Teaching Fellow</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full wp-image-195" src="img/tamara_crop.jpg" alt="Tamara Gheorghes" width="100" height="100">
                <p>&nbsp</p>    
                <p>After an MSc in Advanced Biological Sciences at the University of Liverpool, Tamara did a PhD on Motion Perception at Sheffield Hallam University. She then joined the Department of Neuroscience, Psychology and Behaviour at the University of Leicester as a Teaching Fellow. Her research interests include visual illusions in trajectory perception, evolutionary frameworks for cognitive processes, and the effects of sleep on cognition. In the Visuo-Motor Lab she is investigating the sensitivity of eye movements to motion illusions.</p>

                <h2><strong>Tom Griffiths, PhD</strong><br>Research Associate, ERSC IAA</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright wp-image-596" src="img/1617137899543-1-300x300.jpg" alt="" width="101" height="101">
                <p>&nbsp</p>    
                <p>Tom completed a PhD in 2020 at University College London, with a focus on access to eye-gaze control technology for children with cerebral palsy. This work involved experimental design, observation of children’s functional vision and looking behaviours and exploration of how these correlated with performance using an eye-gaze system. Tom has worked as a Clinical Scientist in the NHS, providing assistive technology (including eye-gaze) for children and adults with congenital and acquired disabilities. He has been involved in several projects and labs, including the <a href="https://www.ucl.ac.uk/gaze/looking-seeing-and-communicating">Gaze Project based at UCL</a> and the international collaboration <a href="https://www.cp-achieve.org.au/resources/publications/2020/stakeholder-consensus-for-decision-making-in-eye-gaze-control-technology-for-children-adolescents-and-adults-with-cerebral-palsy-service-provision-findings-from-a-delphi-study/"><em>EyesOnCommunication</em></a> which established clinical guidelines for the assessment and provision of eye-gaze technology. Tom’s research interests include the practical implementation of research findings in eye-gaze software and ways of supporting people to learn to use this technology.</p>
                <p>Twitter: @TG_AT</p>
                <p>Research Gate: <a href="https://www.researchgate.net/profile/Tom-Griffiths">https://www.researchgate.net/profile/Tom-Griffiths</a></p>
                <h2 style="text-align: center;"><b></b>Former members</h2>

                <h2><strong>Olivia Marsh, MSc</strong><br>Research Technician</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full wp-image-195" src="img/OliviaMarsh.jpg" alt="Olivia Marsh" width="100" height="100">
                <p>&nbsp</p>    
                <p>After obtaining a BSc in Psychology from the University of Leicester, Olivia completed an MSc in Cognitive Neuroscience at the University of East Anglia, where she used eye-tracking to research reading in groups of people with Autism Spectrum Disorder, paying attention to how factors like visual attention and perception influence eye movement behaviour in complex cognitive tasks. She worked on a project funded by the British Academy investigating sensorimotor mechanisms of gaze-controlled technology, and how the interaction between a user and such systems can be improved.</p>
                <p>&nbsp;<img src="img/BA-logo-strap-blue-font-white-300x121.jpg" alt="" width="200"></p>

                <h2><strong>Omar Bachtoula, MSc</strong><br>Visiting PhD student</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full wp-image-195" src="img/omar_resized.jpg" alt="" width="100" height="100">
                <p>&nbsp</p>    
                <p>Omar obtained an MSc in Statistical and mathematical methods applied to behavioural research. He started his PhD in 2020 supported by a fellowship from the Ministerio de Ciencia, Innovación y Universidades (Spain), under the supervision of Prof Ignacio Serrano-Pedraza at the Universidad Complutense de Madrid. His main interests are on binocular interactions in motion perception. During his visit in the Visuo-Motor Lab Omar looked at the processing of reafference during smooth pursuit eye movements by looking at ocular following responses to background motion. He is presenting his work at ECVP 2022 in Nijmegen.</p>

                <h2><strong>Raul Luna Del Valle, MSc</strong><br>Visiting PhD student</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full wp-image-195" src="img/raul-e1560587380897.jpg" alt="" width="100" height="100">
                <p>&nbsp</p>    
                <p>Raúl obtained a BSc in Psychology and further completed an MSc on statistical and mathematical methods applied to behavioural research. He is doing his PhD in the field of visual psychophysics at the Universidad Complutense de Madrid, where he studies the inhibitory interaction between motion sensors tuned to coarse and fine spatial scales under the supervision of Prof <a href="https://www.ucm.es/serranopedrazalab/people">Ignacio Serrano-Pedraza</a>. Raúl’s interests mainly focus on 2D motion perception, although he also has some experience in 3D motion perception and spatial vision. During the summer months he studied recalibration to background motion during pursuit eye movements in the Visuo-Motor Lab.</p>

                <h2><strong>Kyle Nacilla, MSc</strong></h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-medium wp-image-202" src="img/Nacilla-k-300x300.jpg" alt="" width="100" height="100">
                <p>&nbsp</p>    
                <p><br>Kyle investigated smooth pursuit eye movements towards biological motion during his master's degree.&nbsp;</p>

                <h2><strong>Jayesha Chudasama, MSc</strong></h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full wp-image-235" src="img/06-e1533808576129.jpg" alt="" width="100" height="100">
                <p>&nbsp</p>    
                <p><br><a href="https://www.linkedin.com/in/jayeshachudasama/">Jayesha</a> was on a work placement in the lab investigating how smooth pursuit eye movements affect motion coherence. She is now a PhD student at the University of Manchester, investigating the relationship between motor systems and language processing using a range of neuroimaging techniques.

                <h2><strong>Jack Higgins</strong><br>Medical Student (3rd year)</h2>
                <p>&nbsp</p>    
                <img class="circle-image alignright size-full wp-image-195" src="img/jack2.jpg" alt="Jack Higgins" width="100" height="100">
                <p>&nbsp</p>    

                <p>Jack volunteered to contribute to the gaze-typing project while being a Medical School undergraduate.</p>

                <h2 id="funding">Funding</h2>

                <h4>Undergraduate students</h4>

                <p>January is a good time to discuss applications to summer research placement schemes (e.g. Welcome Trust).</p>

                <h4>PhD studentships</h4>

                <p>I regularly submit projects eligible for the <a href="https://www2.warwick.ac.uk/fac/cross_fac/mibtp/">Midlands Integrative Biosciences Training Partnership (MIBTP)</a>, a doctoral training partnership between Birmingham, Warwick and Leicester, funded by the BBSRC.</p>

                <h4>Post-doc fellowships</h4>

                <p>As a former Humboldt fellow, German nationals can apply for funding to work in the lab via the Feodor Lynen Research Fellowship for new or experienced postdocs from the Alexander von Humboldt foundation.</p>
                <p>David is happy to discuss other funding opportunities by email or in person.</p>
                
                <p>&nbsp</p>    
                <p> This page was created using the "Plain Academic" template you can find on <a href="https://github.com/mavroudisv/plain-academic">GitHub</a></p> 
                <p>&nbsp</p>    
            </div>
        </div>
    </div>    
</body>

</html>